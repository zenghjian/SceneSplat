#!/usr/bin/env python3
"""
å•åœºæ™¯è¯­è¨€æ¨¡å‹æ¨ç†æµ‹è¯•
"""
import sys
import os
import torch
import numpy as np
sys.path.insert(0, os.path.abspath('.'))

from pointcept.utils.config import Config
from pointcept.models import build_model
from datetime import datetime
import pickle

def test_single_scene():
    print("SceneSplat å•åœºæ™¯è¯­è¨€æ¨¡å‹æ¨ç†æµ‹è¯•")
    print("=" * 50)
    
    # åœºæ™¯è·¯å¾„
    scene_path = "/home/huajianzeng/project/SceneSplat/sample/scene0708_00_0"
    
    print("1. åŠ è½½åœºæ™¯æ•°æ®...")
    try:
        coord = np.load(os.path.join(scene_path, 'coord.npy'))
        color = np.load(os.path.join(scene_path, 'color.npy'))
        opacity = np.load(os.path.join(scene_path, 'opacity.npy'))
        quat = np.load(os.path.join(scene_path, 'quat.npy'))
        scale = np.load(os.path.join(scene_path, 'scale.npy'))
        lang_feat = np.load(os.path.join(scene_path, 'lang_feat.npy'))
        
        print(f"   åæ ‡å½¢çŠ¶: {coord.shape}")
        print(f"   é¢œè‰²å½¢çŠ¶: {color.shape}")
        print(f"   é€æ˜åº¦å½¢çŠ¶: {opacity.shape}")
        print(f"   å››å…ƒæ•°å½¢çŠ¶: {quat.shape}")
        print(f"   ç¼©æ”¾å½¢çŠ¶: {scale.shape}")
        print(f"   è¯­è¨€ç‰¹å¾å½¢çŠ¶: {lang_feat.shape}")
        
        # ç»„åˆç‰¹å¾ (color:3 + quat:4 + scale:3 + opacity:1 = 11ç»´)
        feat = np.concatenate([color, quat, scale, opacity[:, None]], axis=1)
        print(f"   ç»„åˆç‰¹å¾å½¢çŠ¶: {feat.shape}")
        
        # ç”±äºGPUå†…å­˜é™åˆ¶ï¼Œåªä½¿ç”¨å‰10000ä¸ªç‚¹è¿›è¡Œæµ‹è¯•
        n_points = min(10000, len(coord))
        coord = coord[:n_points]
        color = color[:n_points]
        opacity = opacity[:n_points]
        quat = quat[:n_points]
        scale = scale[:n_points]
        lang_feat = lang_feat[:n_points]
        feat = np.concatenate([color, quat, scale, opacity[:, None]], axis=1)
        
        print(f"   >> ä½¿ç”¨å­é›†è¿›è¡Œæµ‹è¯•: {n_points} ä¸ªç‚¹")
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False
    
    print("\n2. åŠ è½½æ¨¡å‹é…ç½®...")
    try:
        cfg = Config.fromfile('/home/huajianzeng/project/SceneSplat/configs/concat_dataset/lang-pretrain-concat-scan-ppv2-matt-mcmc-wo-normal-contrastive.py')
        print("   âœ… é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    print("\n3. æ„å»ºæ¨¡å‹...")
    try:
        model = build_model(cfg.model)
        model = model.cuda()
        print(f"   âœ… æ¨¡å‹æ„å»ºæˆåŠŸ: {type(model)}")
        print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    except Exception as e:
        print(f"   âŒ æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
        return False
    
    print("\n4. åŠ è½½é¢„è®­ç»ƒæƒé‡...")
    try:
        checkpoint = torch.load('/home/huajianzeng/project/SceneSplat/models/pretrained/scenesplat_main/model_best.pth', weights_only=False)
        
        # æ¸…ç†æƒé‡åç§°
        from collections import OrderedDict
        weight = OrderedDict()
        for key, value in checkpoint["state_dict"].items():
            if key.startswith("module."):
                key = key[7:]  # å»é™¤ module. å‰ç¼€
            weight[key] = value
        
        model.load_state_dict(weight, strict=True)
        print(f"   âœ… æƒé‡åŠ è½½æˆåŠŸ (epoch {checkpoint.get('epoch', 'unknown')})")
    except Exception as e:
        print(f"   âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return False
    
    print("\n5. å‡†å¤‡è¾“å…¥æ•°æ®...")
    try:
        # è½¬æ¢ä¸ºtensor (ä¸éœ€è¦batchç»´åº¦ï¼Œç›´æ¥ä¼ å…¥)
        coord = torch.from_numpy(coord).float().cuda()  # [N, 3]
        feat = torch.from_numpy(feat).float().cuda()    # [N, 11]
        lang_feat = torch.from_numpy(lang_feat).float().cuda()  # [N, D]
        
        print(f"   è¾“å…¥åæ ‡: {coord.shape}")
        print(f"   è¾“å…¥ç‰¹å¾: {feat.shape}")
        print(f"   è¯­è¨€ç‰¹å¾: {lang_feat.shape}")
        
    except Exception as e:
        print(f"   âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        return False
    
    print("\n6. è¿è¡Œå‰å‘æ¨ç†...")
    try:
        model.eval()
        with torch.no_grad():
            # æ„å»ºè¾“å…¥å­—å…¸
            input_dict = {
                'coord': coord,
                'feat': feat,
                'lang_feat': lang_feat,
                'offset': torch.tensor([0, coord.shape[0]], device='cuda'),  # [0, N]
                'grid_size': 0.02,  # æ·»åŠ ç½‘æ ¼å¤§å°
            }
            
            print("   å¼€å§‹æ¨ç†...")
            output = model(input_dict)
            print(f"   âœ… æ¨ç†æˆåŠŸ!")
            
            # ä¿å­˜æ¨ç†ç»“æœ (ç®€åŒ–ç‰ˆ)
            from save_inference_features_simple import save_inference_output_simple
            scene_name = os.path.basename(scene_path)
            saved_files = save_inference_output_simple(output, input_dict, scene_name)
            
            return True, output
            
    except Exception as e:
        print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def save_results(output, input_dict, scene_path):
    """ä¿å­˜æ¨ç†ç»“æœåˆ°resultsç›®å½•"""
    print("\n7. ä¿å­˜æ¨ç†ç»“æœ...")
    
    # åˆ›å»ºresultsç›®å½•
    results_dir = "/home/huajianzeng/project/SceneSplat/results"
    os.makedirs(results_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    scene_name = os.path.basename(scene_path)
    
    saved_files = {}
    
    try:
        # 1. ä¿å­˜æ‰€æœ‰è¾“å‡ºæ•°æ®
        print("   æ­£åœ¨åˆ†æè¾“å‡ºç»“æ„...")
        
        if isinstance(output, dict):
            print(f"   å‘ç°è¾“å‡ºå­—å…¸ï¼Œé”®: {list(output.keys())}")
            
            # ä¿å­˜å®Œæ•´è¾“å‡ºå­—å…¸ (pickleæ ¼å¼ï¼Œä¿æŒåŸå§‹ç»“æ„)
            output_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_full_output.pkl")
            with open(output_file, 'wb') as f:
                # å°†æ‰€æœ‰tensorç§»åˆ°CPUå†ä¿å­˜
                output_cpu = {}
                for k, v in output.items():
                    if isinstance(v, torch.Tensor):
                        output_cpu[k] = v.detach().cpu()
                    elif hasattr(v, 'feat') and hasattr(v, 'coord'):
                        # Pointå¯¹è±¡
                        point_cpu = type(v)()
                        for attr_name in dir(v):
                            if not attr_name.startswith('_') and hasattr(v, attr_name):
                                attr_value = getattr(v, attr_name)
                                if isinstance(attr_value, torch.Tensor):
                                    setattr(point_cpu, attr_name, attr_value.detach().cpu())
                                elif not callable(attr_value):
                                    setattr(point_cpu, attr_name, attr_value)
                        output_cpu[k] = point_cpu
                    else:
                        output_cpu[k] = v
                pickle.dump(output_cpu, f)
            
            saved_files['full_output'] = output_file
            print(f"   âœ… å®Œæ•´è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")
            
            # 2. æå–å¹¶ä¿å­˜ä¸»è¦ç‰¹å¾
            for key, value in output.items():
                print(f"   å¤„ç†è¾“å‡ºé¡¹: {key}")
                
                if isinstance(value, torch.Tensor):
                    # ç›´æ¥çš„tensorè¾“å‡º
                    feat_array = value.detach().cpu().numpy()
                    feat_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_{key}.npy")
                    np.save(feat_file, feat_array)
                    saved_files[key] = feat_file
                    print(f"     âœ… {key} å·²ä¿å­˜: {feat_file} (å½¢çŠ¶: {feat_array.shape})")
                
                elif hasattr(value, 'feat') and value.feat is not None:
                    # Pointå¯¹è±¡çš„feat
                    feat_array = value.feat.detach().cpu().numpy()
                    feat_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_{key}_feat.npy")
                    np.save(feat_file, feat_array)
                    saved_files[f'{key}_feat'] = feat_file
                    print(f"     âœ… {key}.feat å·²ä¿å­˜: {feat_file} (å½¢çŠ¶: {feat_array.shape})")
                    
                    # Pointå¯¹è±¡çš„coord
                    if hasattr(value, 'coord') and value.coord is not None:
                        coord_array = value.coord.detach().cpu().numpy()
                        coord_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_{key}_coord.npy")
                        np.save(coord_array, coord_file)
                        saved_files[f'{key}_coord'] = coord_file
                        print(f"     âœ… {key}.coord å·²ä¿å­˜: {coord_file} (å½¢çŠ¶: {coord_array.shape})")
                    
                    # Pointå¯¹è±¡çš„å…¶ä»–å±æ€§
                    for attr_name in ['grid_coord', 'serialized_code', 'index', 'offset']:
                        if hasattr(value, attr_name):
                            attr_value = getattr(value, attr_name)
                            if attr_value is not None and isinstance(attr_value, torch.Tensor):
                                attr_array = attr_value.detach().cpu().numpy()
                                attr_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_{key}_{attr_name}.npy")
                                np.save(attr_file, attr_array)
                                saved_files[f'{key}_{attr_name}'] = attr_file
                                print(f"     âœ… {key}.{attr_name} å·²ä¿å­˜: {attr_file} (å½¢çŠ¶: {attr_array.shape})")
                
                else:
                    print(f"     âš ï¸ {key}: æœªçŸ¥ç±»å‹ {type(value)}")
        
        elif isinstance(output, torch.Tensor):
            # ç›´æ¥tensorè¾“å‡º
            feat_array = output.detach().cpu().numpy()
            feat_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_output_tensor.npy")
            np.save(feat_file, feat_array)
            saved_files['output_tensor'] = feat_file
            print(f"   âœ… è¾“å‡ºtensorå·²ä¿å­˜åˆ°: {feat_file} (å½¢çŠ¶: {feat_array.shape})")
        
        # 2. ä¿å­˜è¾“å…¥ç‰¹å¾ç”¨äºå¯¹æ¯”
        input_feat_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_input_features.npy")
        input_lang_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_input_lang_features.npy")
        
        np.save(input_feat_file, input_dict['feat'].cpu().numpy())
        np.save(input_lang_file, input_dict['lang_feat'].cpu().numpy())
        
        print(f"   âœ… è¾“å…¥å‡ ä½•ç‰¹å¾å·²ä¿å­˜åˆ°: {input_feat_file}")
        print(f"   âœ… è¾“å…¥è¯­è¨€ç‰¹å¾å·²ä¿å­˜åˆ°: {input_lang_file}")
        
        # 3. ä¿å­˜è¾“å…¥ä¿¡æ¯
        input_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_input_info.txt")
        with open(input_file, 'w') as f:
            f.write(f"SceneSplat è¯­è¨€æ¨¡å‹æ¨ç† - è¾“å…¥ä¿¡æ¯\n")
            f.write(f"=" * 50 + "\n\n")
            f.write(f"æ—¶é—´æˆ³: {timestamp}\n")
            f.write(f"åœºæ™¯è·¯å¾„: {scene_path}\n")
            f.write(f"åœºæ™¯åç§°: {scene_name}\n\n")
            
            for key, value in input_dict.items():
                if isinstance(value, torch.Tensor):
                    f.write(f"{key}: å½¢çŠ¶={value.shape}, ç±»å‹={value.dtype}\n")
                else:
                    f.write(f"{key}: {type(value)} = {value}\n")
        
        print(f"   âœ… è¾“å…¥ä¿¡æ¯å·²ä¿å­˜åˆ°: {input_file}")
        
        # 4. åˆ›å»ºæ¨ç†æ‘˜è¦
        summary_file = os.path.join(results_dir, f"{scene_name}_{timestamp}_summary.txt")
        with open(summary_file, 'w') as f:
            f.write(f"SceneSplat è¯­è¨€æ¨¡å‹æ¨ç†æ‘˜è¦\n")
            f.write(f"=" * 50 + "\n\n")
            f.write(f"æ¨ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åœºæ™¯: {scene_name}\n")
            f.write(f"è¾“å…¥ç‚¹æ•°: {input_dict['coord'].shape[0]}\n")
            f.write(f"è¾“å…¥å‡ ä½•ç‰¹å¾ç»´åº¦: {input_dict['feat'].shape[1]}\n")
            f.write(f"è¾“å…¥è¯­è¨€ç‰¹å¾ç»´åº¦: {input_dict['lang_feat'].shape[1]}\n")
            
            if isinstance(output, dict) and 'point_feat' in output:
                point_feat = output['point_feat']
                if hasattr(point_feat, 'feat'):
                    f.write(f"è¾“å‡ºç‰¹å¾ç»´åº¦: {point_feat.feat.shape[1]}\n")
                    f.write(f"è¾“å‡ºç‰¹å¾èŒƒå›´: [{point_feat.feat.min().item():.6f}, {point_feat.feat.max().item():.6f}]\n")
                    f.write(f"è¾“å‡ºç‰¹å¾å‡å€¼: {point_feat.feat.mean().item():.6f}\n")
                    f.write(f"è¾“å‡ºç‰¹å¾æ ‡å‡†å·®: {point_feat.feat.std().item():.6f}\n")
                    
                    # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
                    input_lang_on_gpu = input_dict['lang_feat']
                    cosine_sim = torch.nn.functional.cosine_similarity(
                        point_feat.feat, input_lang_on_gpu, dim=1
                    ).mean().item()
                    f.write(f"ä¸è¾“å…¥è¯­è¨€ç‰¹å¾ç›¸ä¼¼åº¦: {cosine_sim:.6f}\n")
            
            f.write(f"\nç”Ÿæˆçš„æ–‡ä»¶:\n")
            if 'feat_file' in locals():
                f.write(f"- è¾“å‡ºç‰¹å¾å‘é‡: {os.path.basename(feat_file)}\n")
            if 'coord_file' in locals():
                f.write(f"- è¾“å‡ºåæ ‡ä¿¡æ¯: {os.path.basename(coord_file)}\n")
            if 'input_feat_file' in locals():
                f.write(f"- è¾“å…¥å‡ ä½•ç‰¹å¾: {os.path.basename(input_feat_file)}\n")
                f.write(f"- è¾“å…¥è¯­è¨€ç‰¹å¾: {os.path.basename(input_lang_file)}\n")
            f.write(f"- è¾“å…¥ä¿¡æ¯: {os.path.basename(input_file)}\n")
            f.write(f"- æ¨ç†æ‘˜è¦: {os.path.basename(summary_file)}\n")
        
        print(f"   âœ… æ¨ç†æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {results_dir}")
        
        return results_dir
        
    except Exception as e:
        print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def analyze_output(output, input_coord, input_feat, input_lang_feat):
    """è¯¦ç»†åˆ†ææ¨ç†è¾“å‡º"""
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¨ç†è¾“å‡ºè¯¦ç»†åˆ†æ")
    print("=" * 50)
    
    if output is None:
        print("âŒ æ— è¾“å‡ºç»“æœå¯åˆ†æ")
        return
    
    print(f"1. è¾“å‡ºæ•°æ®ç»“æ„:")
    print(f"   ç±»å‹: {type(output)}")
    
    if isinstance(output, dict):
        print(f"   å­—å…¸é”®: {list(output.keys())}")
        
        for key, value in output.items():
            print(f"\n2. è¾“å‡ºé¡¹: {key}")
            if isinstance(value, torch.Tensor):
                print(f"   - å½¢çŠ¶: {value.shape}")
                print(f"   - æ•°æ®ç±»å‹: {value.dtype}")
                print(f"   - è®¾å¤‡: {value.device}")
                print(f"   - å€¼èŒƒå›´: [{value.min().item():.6f}, {value.max().item():.6f}]")
                print(f"   - å‡å€¼: {value.mean().item():.6f}")
                print(f"   - æ ‡å‡†å·®: {value.std().item():.6f}")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªå€¼çš„æ ·æœ¬
                if value.numel() <= 20:
                    print(f"   - æ‰€æœ‰å€¼: {value.flatten()[:10].cpu().tolist()}")
                else:
                    print(f"   - å‰10ä¸ªå€¼: {value.flatten()[:10].cpu().tolist()}")
                    
            elif hasattr(value, 'feat') and hasattr(value, 'coord'):
                # Pointå¯¹è±¡
                print(f"   - Pointå¯¹è±¡å±æ€§:")
                if hasattr(value, 'feat') and value.feat is not None:
                    feat_tensor = value.feat
                    print(f"     * featå½¢çŠ¶: {feat_tensor.shape}")
                    print(f"     * featæ•°æ®ç±»å‹: {feat_tensor.dtype}")
                    print(f"     * featå€¼èŒƒå›´: [{feat_tensor.min().item():.6f}, {feat_tensor.max().item():.6f}]")
                    print(f"     * featå‡å€¼: {feat_tensor.mean().item():.6f}")
                    print(f"     * featæ ‡å‡†å·®: {feat_tensor.std().item():.6f}")
                
                if hasattr(value, 'coord') and value.coord is not None:
                    coord_tensor = value.coord
                    print(f"     * coordå½¢çŠ¶: {coord_tensor.shape}")
                    print(f"     * coordå€¼èŒƒå›´: [{coord_tensor.min().item():.6f}, {coord_tensor.max().item():.6f}]")
                
                # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„å±æ€§
                attrs = ['grid_coord', 'serialized_code', 'index', 'additional']
                for attr in attrs:
                    if hasattr(value, attr):
                        attr_value = getattr(value, attr)
                        if attr_value is not None:
                            if isinstance(attr_value, torch.Tensor):
                                print(f"     * {attr}å½¢çŠ¶: {attr_value.shape}")
                            else:
                                print(f"     * {attr}ç±»å‹: {type(attr_value)}")
            else:
                print(f"   - å…¶ä»–ç±»å‹: {type(value)}")
                print(f"   - å­—ç¬¦ä¸²è¡¨ç¤º: {str(value)[:100]}...")
    
    elif isinstance(output, torch.Tensor):
        print(f"   - å½¢çŠ¶: {output.shape}")
        print(f"   - æ•°æ®ç±»å‹: {output.dtype}")
        print(f"   - è®¾å¤‡: {output.device}")
        print(f"   - å€¼èŒƒå›´: [{output.min().item():.6f}, {output.max().item():.6f}]")
        print(f"   - å‡å€¼: {output.mean().item():.6f}")
        print(f"   - æ ‡å‡†å·®: {output.std().item():.6f}")
    
    # å¯¹æ¯”è¾“å…¥è¾“å‡º
    print(f"\n3. è¾“å…¥è¾“å‡ºå¯¹æ¯”:")
    print(f"   è¾“å…¥ç‚¹æ•°: {input_coord.shape[0]}")
    print(f"   è¾“å…¥ç‰¹å¾ç»´åº¦: {input_feat.shape[1]}")
    print(f"   è¾“å…¥è¯­è¨€ç‰¹å¾ç»´åº¦: {input_lang_feat.shape[1]}")
    
    if isinstance(output, dict) and 'point_feat' in output:
        point_feat = output['point_feat']
        if hasattr(point_feat, 'feat'):
            print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {point_feat.feat.shape[1] if point_feat.feat.ndim > 1 else 'scalar'}")
            print(f"   ç‰¹å¾ç»´åº¦å˜åŒ–: {input_feat.shape[1]} -> {point_feat.feat.shape[1] if point_feat.feat.ndim > 1 else 'scalar'}")
    
    # æ·±åº¦ç‰¹å¾åˆ†æ
    print(f"\n4. ç‰¹å¾æ„æˆåˆ†æ:")
    if isinstance(output, dict) and 'point_feat' in output:
        point_feat = output['point_feat']
        if hasattr(point_feat, 'feat'):
            output_feat = point_feat.feat
            print(f"   è¾“å‡ºç‰¹å¾ç»´åº¦: {output_feat.shape[1]}")
            print(f"   è¾“å…¥è¯­è¨€ç‰¹å¾ç»´åº¦: {input_lang_feat.shape[1]}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸è¾“å…¥è¯­è¨€ç‰¹å¾ç›¸ä¼¼
            if output_feat.shape[1] == input_lang_feat.shape[1]:
                print(f"   âœ… è¾“å‡ºç‰¹å¾ç»´åº¦ä¸è¾“å…¥è¯­è¨€ç‰¹å¾ä¸€è‡´ ({output_feat.shape[1]}ç»´)")
                
                # è®¡ç®—ä¸è¾“å…¥è¯­è¨€ç‰¹å¾çš„ç›¸ä¼¼æ€§
                input_lang_on_gpu = input_lang_feat.cuda()
                cosine_sim = torch.nn.functional.cosine_similarity(
                    output_feat, input_lang_on_gpu, dim=1
                ).mean().item()
                
                print(f"   ä¸è¾“å…¥è¯­è¨€ç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim:.6f}")
                
                if cosine_sim > 0.8:
                    print(f"   ğŸ” é«˜ç›¸ä¼¼åº¦ - è¾“å‡ºå¯èƒ½ä¸»è¦ä¿æŒäº†è¾“å…¥è¯­è¨€ç‰¹å¾")
                elif cosine_sim > 0.3:
                    print(f"   ğŸ” ä¸­ç­‰ç›¸ä¼¼åº¦ - è¾“å‡ºæ˜¯è¯­è¨€ç‰¹å¾ä¸å‡ ä½•ç‰¹å¾çš„èåˆ")
                else:
                    print(f"   ğŸ” ä½ç›¸ä¼¼åº¦ - è¾“å‡ºæ˜¯å¤§å¹…å˜æ¢åçš„ç‰¹å¾")
                
                # åˆ†æç‰¹å¾å˜åŒ–
                input_lang_stats = {
                    'mean': input_lang_on_gpu.mean().item(),
                    'std': input_lang_on_gpu.std().item(),
                    'min': input_lang_on_gpu.min().item(),
                    'max': input_lang_on_gpu.max().item()
                }
                
                output_stats = {
                    'mean': output_feat.mean().item(),
                    'std': output_feat.std().item(),
                    'min': output_feat.min().item(),
                    'max': output_feat.max().item()
                }
                
                print(f"\n   è¾“å…¥è¯­è¨€ç‰¹å¾ç»Ÿè®¡:")
                print(f"     å‡å€¼: {input_lang_stats['mean']:.6f}")
                print(f"     æ ‡å‡†å·®: {input_lang_stats['std']:.6f}")
                print(f"     èŒƒå›´: [{input_lang_stats['min']:.6f}, {input_lang_stats['max']:.6f}]")
                
                print(f"\n   è¾“å‡ºç‰¹å¾ç»Ÿè®¡:")
                print(f"     å‡å€¼: {output_stats['mean']:.6f}")
                print(f"     æ ‡å‡†å·®: {output_stats['std']:.6f}")
                print(f"     èŒƒå›´: [{output_stats['min']:.6f}, {output_stats['max']:.6f}]")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å‡ ä½•ä¿¡æ¯çš„ç¼–ç 
                print(f"\n   å‡ ä½•ç‰¹å¾èåˆåˆ†æ:")
                print(f"   è¾“å…¥å‡ ä½•ç‰¹å¾ç»´åº¦: {input_feat.shape[1]}ç»´")
                
                # ç®€å•çš„çº¿æ€§ç›¸å…³æ€§æ£€æŸ¥
                geometry_feat_expanded = input_feat.cuda().unsqueeze(-1).expand(-1, -1, output_feat.shape[1] // input_feat.shape[1])
                geometry_feat_flat = geometry_feat_expanded.reshape(input_feat.shape[0], -1)[:, :output_feat.shape[1]]
                
                if geometry_feat_flat.shape[1] == output_feat.shape[1]:
                    geo_corr = torch.nn.functional.cosine_similarity(
                        output_feat, geometry_feat_flat, dim=1
                    ).mean().item()
                    print(f"   ä¸å‡ ä½•ç‰¹å¾çš„ç›¸å…³æ€§: {geo_corr:.6f}")
                    
                    if abs(geo_corr) > 0.1:
                        print(f"   ğŸ” æ£€æµ‹åˆ°å‡ ä½•ç‰¹å¾å½±å“")
                    else:
                        print(f"   ğŸ” å‡ ä½•ç‰¹å¾å½±å“è¾ƒå°")
            else:
                print(f"   è¾“å‡ºç»´åº¦ä¸è¯­è¨€ç‰¹å¾ä¸åŒï¼Œå¯èƒ½æ˜¯æ··åˆè¡¨ç¤º")
    
    
    # ä¿å­˜åˆ†æç»“æœ
    print(f"\n6. ç»“æœä¿å­˜:")
    analysis_file = "/home/huajianzeng/project/SceneSplat/inference_analysis.txt"
    try:
        with open(analysis_file, 'w') as f:
            f.write("SceneSplat è¯­è¨€æ¨¡å‹æ¨ç†è¾“å‡ºåˆ†æ\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"è¾“å‡ºç±»å‹: {type(output)}\n")
            if isinstance(output, dict):
                for key, value in output.items():
                    f.write(f"\n{key}:\n")
                    if isinstance(value, torch.Tensor):
                        f.write(f"  å½¢çŠ¶: {value.shape}\n")
                        f.write(f"  æ•°æ®ç±»å‹: {value.dtype}\n")
                        f.write(f"  å€¼èŒƒå›´: [{value.min().item():.6f}, {value.max().item():.6f}]\n")
                        f.write(f"  å‡å€¼: {value.mean().item():.6f}\n")
                    elif hasattr(value, 'feat'):
                        f.write(f"  Pointå¯¹è±¡ - featå½¢çŠ¶: {value.feat.shape}\n")
        print(f"   âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
    except Exception as e:
        print(f"   âš ï¸ ä¿å­˜å¤±è´¥: {e}")

if __name__ == "__main__":
    result = test_single_scene()
    if isinstance(result, tuple):
        success, output = result
        if success:
            print("\nğŸ‰ å•åœºæ™¯è¯­è¨€æ¨¡å‹æ¨ç†æµ‹è¯•æˆåŠŸ!")
            
            # é‡æ–°åŠ è½½æ•°æ®è¿›è¡Œåˆ†æå¯¹æ¯”
            scene_path = "/home/huajianzeng/project/SceneSplat/scannet_mcmc_3dgs_preprocessed/test_grid1.0cm_chunk6x6_stride3x3/scene0708_00_0"
            coord = np.load(os.path.join(scene_path, 'coord.npy'))
            color = np.load(os.path.join(scene_path, 'color.npy'))
            opacity = np.load(os.path.join(scene_path, 'opacity.npy'))
            quat = np.load(os.path.join(scene_path, 'quat.npy'))
            scale = np.load(os.path.join(scene_path, 'scale.npy'))
            lang_feat = np.load(os.path.join(scene_path, 'lang_feat.npy'))
            
            # ä½¿ç”¨ç›¸åŒçš„å­é›†
            n_points = min(10000, len(coord))
            coord = coord[:n_points]
            color = color[:n_points]
            opacity = opacity[:n_points]
            quat = quat[:n_points]  
            scale = scale[:n_points]
            lang_feat = lang_feat[:n_points]
            feat = np.concatenate([color, quat, scale, opacity[:, None]], axis=1)
            
            # è½¬æ¢ä¸ºtensorç”¨äºå¯¹æ¯”
            coord_tensor = torch.from_numpy(coord).float()
            feat_tensor = torch.from_numpy(feat).float()
            lang_feat_tensor = torch.from_numpy(lang_feat).float()
            
            # åˆ†æè¾“å‡º
            analyze_output(output, coord_tensor, feat_tensor, lang_feat_tensor)
            
        else:
            print("\nâŒ æ¨ç†æµ‹è¯•å¤±è´¥")
    else:
        # å…¼å®¹æ—§ç‰ˆæœ¬è¿”å›å€¼
        success = result
        if success:
            print("\nğŸ‰ å•åœºæ™¯è¯­è¨€æ¨¡å‹æ¨ç†æµ‹è¯•æˆåŠŸ!")
        else:
            print("\nâŒ æ¨ç†æµ‹è¯•å¤±è´¥")
    
    sys.exit(0 if success else 1)